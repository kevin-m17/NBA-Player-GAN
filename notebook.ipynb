{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[WDM] - Current google-chrome version is 85.0.4183\nINFO:WDM:Current google-chrome version is 85.0.4183\n[WDM] - Get LATEST driver version for 85.0.4183\nINFO:WDM:Get LATEST driver version for 85.0.4183\n[WDM] - Driver [/Users/kevinmo/.wdm/drivers/chromedriver/mac64/85.0.4183.87/chromedriver] found in cache\nINFO:WDM:Driver [/Users/kevinmo/.wdm/drivers/chromedriver/mac64/85.0.4183.87/chromedriver] found in cache\n \naiazng\n"
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "# driver = webdriver.Chrome(\"C:Downloads/chromedriver\")\n",
    "# browser = webdriver.Chrome()\n",
    "\n",
    "URL = \"https://www.nba.com/players\"\n",
    "browser.get(URL)\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, 'html5lib')\n",
    "# time.sleep(1)\n",
    "\n",
    "elem = browser.find_element_by_tag_name(\"body\")\n",
    "\n",
    "no_of_pagedowns = 120\n",
    "\n",
    "while no_of_pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    # time.sleep(0.2)\n",
    "    no_of_pagedowns-=1\n",
    "\n",
    "# after scrolling, I make a new folder\n",
    "src = \"./originalPics\"\n",
    "os.mkdir(src)\n",
    "\n",
    "digit = 1\n",
    "# nbaImages = soup.findAll('img', attrs = {'class':'lazyloaded'})\n",
    "# nbaImages = soup.findAll('img', attrs = {'class':'lazyload'})\n",
    "\n",
    "post_elems = browser.find_elements_by_class_name(\"lazyload\")\n",
    "post_elems = browser.find_elements_by_class_name(\"lazyloaded\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "for post in post_elems:\n",
    "    # get the image link\n",
    "    link = post.get_attribute(\"data-src\")\n",
    "    if link[:2] == \"//\":\n",
    "        link = \"https://\" + link[2:]\n",
    "\n",
    "    if count == 250:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    # name of the file\n",
    "    filename = \"nba\" + str(count)\n",
    "\n",
    "    # actually write the image in the folder\n",
    "    mergeFile = os.path.join(src, filename + \".jpeg\")\n",
    "    output = open(mergeFile, 'wb')\n",
    "    output.write(urllib.request.urlopen(link).read())\n",
    "    output.close()\n",
    "\n",
    "# for img in nbaImages:\n",
    "#     link = img.get('data-src')\n",
    "\n",
    "#     if link[:2] == \"//\":\n",
    "#         link = \"https://\" + link[2:]\n",
    "#     print(link) \n",
    "\n",
    "#     if digit == 351:\n",
    "#         break\n",
    "\n",
    "#     strVal = str(digit)\n",
    "#     filename = \"nba\" + strVal\n",
    "#     digit += 1\n",
    "\n",
    "#     mergeFile = os.path.join(src, filename + \".jpeg\")\n",
    "#     output = open(mergeFile, 'wb')\n",
    "#     output.write(urllib.request.urlopen(link).read())\n",
    "#     output.close()\n",
    "\n",
    "# post_elems = browser.find_elements_by_class_name(\"lazyload\")\n",
    "# post_elems = browser.find_elements_by_class_name(\"lazyloaded\")\n",
    "# print(\"aiazng\")\n",
    "# count = 1\n",
    "\n",
    "# for post in post_elems:\n",
    "#     print(str(count))\n",
    "#     count += 1\n",
    "#     print (post.text)\n",
    "# print(\"whats gooddd\")\n",
    "#web scraped NBA photos\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import urllib\n",
    "# import os\n",
    "\n",
    "# URL = \"https://www.nba.com/players\"\n",
    "# r = requests.get(URL)\n",
    "\n",
    "# origin = \"GAN\"\n",
    "# src = \"./originalPics\"\n",
    "\n",
    "# soup = BeautifulSoup(r.content, 'html5lib')\n",
    "# print(soup.prettify()) \n",
    "\n",
    "\n",
    "# digit = 1\n",
    "# nbaImages = soup.findAll('img', attrs = {'class':'lazyloaded'})\n",
    "\n",
    "# os.mkdir(src)\n",
    "\n",
    "# for img in nbaImages:\n",
    "#     link = img.get('data-src')\n",
    "\n",
    "#     if link[:2] == \"//\":\n",
    "#         link = \"https://\" + link[2:]\n",
    "#     print(link) \n",
    "\n",
    "#     if digit == 351:\n",
    "#         break\n",
    "\n",
    "#     strVal = str(digit)\n",
    "#     filename = \"nba\" + strVal\n",
    "#     digit += 1\n",
    "\n",
    "#     mergeFile = os.path.join(src, filename + \".jpeg\")\n",
    "#     output = open(mergeFile, 'wb')\n",
    "#     output.write(urllib.request.urlopen(link).read())\n",
    "#     output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is resizing the images\n",
    "# %matplotlib inline\n",
    "# import os\n",
    "# import PIL\n",
    "# from PIL import Image\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# put images in folder\n",
    "src = \"./originalPics\"\n",
    "dst = \"./resized\"\n",
    "\n",
    "os.mkdir(dst)\n",
    "\n",
    "count = 1\n",
    "\n",
    "for pic in os.listdir(src):\n",
    "    img = cv2.imread(os.path.join(src,pic))\n",
    "    img = cv2.resize(img,(128, 128))\n",
    "    cv2.imwrite(os.path.join(dst,pic), img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "debug\n"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "src = \"resized\"\n",
    "dst = \"./resized_black/\"\n",
    "\n",
    "os.mkdir(dst)\n",
    "\n",
    "for pic in os.listdir(src):\n",
    "    png = Image.open(os.path.join(src,pic))\n",
    "    # print each\n",
    "    if png.mode == 'RGBA':\n",
    "        png.load() # required for png.split()\n",
    "        background = Image.new(\"RGB\", png.size, (0,0,0))\n",
    "        background.paste(png, mask=png.split()[3]) # 3 is the alpha channel\n",
    "        background.save(os.path.join(dst,pic.split('.')[0] + '.jpeg'), 'JPEG') # changed from .jpg\n",
    "    else:\n",
    "        png.convert('RGB')\n",
    "        png.save(os.path.join(dst,pic.split('.')[0] + '.jpeg'), 'JPEG')\n",
    "print(\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: tensorflow==1.15 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (1.15.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\nRequirement already satisfied: astor>=0.6.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.1)\nRequirement already satisfied: absl-py>=0.7.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.10.0)\nRequirement already satisfied: protobuf>=3.6.1 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (3.13.0)\nRequirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.1)\nRequirement already satisfied: keras-applications>=1.0.8 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\nRequirement already satisfied: google-pasta>=0.1.6 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\nRequirement already satisfied: wheel>=0.26 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\nRequirement already satisfied: six>=1.10.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.14.0)\nRequirement already satisfied: tensorflow-estimator==1.15.1 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.1)\nRequirement already satisfied: gast==0.2.2 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\nRequirement already satisfied: wrapt>=1.11.1 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)\nRequirement already satisfied: termcolor>=1.1.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\nRequirement already satisfied: grpcio>=1.8.6 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.32.0)\nRequirement already satisfied: setuptools in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.15) (46.0.0.post20200309)\nRequirement already satisfied: markdown>=2.6.8 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\nRequirement already satisfied: werkzeug>=0.11.15 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.0)\nRequirement already satisfied: h5py in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.5.0)\nRequirement already satisfied: zipp>=0.5 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.2.0)\n1.15.0\nyuh\nhi\n"
    }
   ],
   "source": [
    "!pip install tensorflow==1.15\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import scipy.misc\n",
    "import tf_slim as slim\n",
    "# from python_utils import *\n",
    "from utils import *\n",
    "\n",
    "# slim = tf.contrib.slim\n",
    "print(tf.__version__)\n",
    "\n",
    "# variables needed\n",
    "HEIGHT, WIDTH, CHANNEL = 128, 128, 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 1000\n",
    "version = 'newFaces'\n",
    "newFace_path = './' + version\n",
    "\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello\n"
    }
   ],
   "source": [
    "### LEAKY RELU - if gradient is too small, we add leak to it to keep it going\n",
    "def lrelu(x, n, leak=0.2): \n",
    "    return tf.maximum(x, x * leak, name=n)\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROCESS THE DATA, get two variables (shown at end)\n",
    "\n",
    "def process_data():   \n",
    "    current_dir = os.getcwd()\n",
    "    face_dir = os.path.join(current_dir, 'resized_black')\n",
    "    images = []\n",
    "\n",
    "    # put images in resized black folder\n",
    "    for each in os.listdir(face_dir):\n",
    "        images.append(os.path.join(face_dir,each))\n",
    "\n",
    "    all_images = tf.convert_to_tensor(images, dtype = tf.string)\n",
    "    \n",
    "    images_queue = tf.train.slice_input_producer(\n",
    "                                        [all_images])\n",
    "                                        \n",
    "    content = tf.read_file(images_queue[0])\n",
    "    image = tf.image.decode_jpeg(content, channels = CHANNEL)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta = 0.1)\n",
    "    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1)\n",
    "    # print image.get_shape()\n",
    "    size = [HEIGHT, WIDTH]\n",
    "    image = tf.image.resize_images(image, size)\n",
    "    image.set_shape([HEIGHT,WIDTH,CHANNEL])\n",
    "    # image = image + noise\n",
    "    \n",
    "    # get rid of tf warning\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    iamges_batch = tf.train.shuffle_batch(\n",
    "                                    [image], batch_size = BATCH_SIZE,\n",
    "                                    num_threads = 4, capacity = 200 + 3* BATCH_SIZE,\n",
    "                                    min_after_dequeue = 200)\n",
    "    num_images = len(images)\n",
    "\n",
    "# returns batch of photos and quantity of images\n",
    "    return iamges_batch, num_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello\n"
    }
   ],
   "source": [
    "# generator network\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def generator(input, random_dim, is_train, reuse=False):\n",
    "    # used for network\n",
    "    c4, c8, c16, c32, c64 = 512, 256, 128, 64, 32 \n",
    "    s4 = 4\n",
    "    output_dim = CHANNEL  \n",
    "    with tf.variable_scope('gen') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # build convolution and the layers of the network\n",
    "        #1\n",
    "        w1 = tf.get_variable('w1', shape=[random_dim, s4 * s4 * c4], dtype=tf.float32,\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b1 = tf.get_variable('b1', shape=[c4 * s4 * s4], dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "        flat_conv1 = tf.add(tf.matmul(input, w1), b1, name='flat_conv1')\n",
    "        conv1 = tf.reshape(flat_conv1, shape=[-1, s4, s4, c4], name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
    "        act1 = tf.nn.relu(bn1, name='act1')\n",
    "        #2\n",
    "        conv2 = tf.layers.conv2d_transpose(act1, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = tf.nn.relu(bn2, name='act2')\n",
    "        #3\n",
    "        conv3 = tf.layers.conv2d_transpose(act2, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = tf.nn.relu(bn3, name='act3')\n",
    "        #4\n",
    "        conv4 = tf.layers.conv2d_transpose(act3, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = tf.nn.relu(bn4, name='act4')\n",
    "        #5\n",
    "        conv5 = tf.layers.conv2d_transpose(act4, c64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv5')\n",
    "        bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n",
    "        act5 = tf.nn.relu(bn5, name='act5')\n",
    "        \n",
    "        #6\n",
    "        conv6 = tf.layers.conv2d_transpose(act5, output_dim, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv6')\n",
    "        # bn6 = tf.contrib.layers.batch_norm(conv6, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn6')\n",
    "        act6 = tf.nn.tanh(conv6, name='act6')\n",
    "        return act6\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello\n"
    }
   ],
   "source": [
    "#### discriminator network\n",
    "def discriminator(input, is_train, reuse=False):\n",
    "    c2, c4, c8, c16 = 64, 128, 256, 512  \n",
    "    with tf.variable_scope('dis') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # layers of discriminator network\n",
    "        #1\n",
    "        conv1 = tf.layers.conv2d(input, c2, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn1')\n",
    "        act1 = lrelu(conv1, n='act1')\n",
    "        #2\n",
    "        conv2 = tf.layers.conv2d(act1, c4, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = lrelu(bn2, n='act2')\n",
    "        #3\n",
    "        conv3 = tf.layers.conv2d(act2, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = lrelu(bn3, n='act3')\n",
    "         #4\n",
    "        conv4 = tf.layers.conv2d(act3, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = lrelu(bn4, n='act4')\n",
    "       \n",
    "        # start from 4th layer\n",
    "        dim = int(np.prod(act4.get_shape()[1:]))\n",
    "        fc1 = tf.reshape(act4, shape=[-1, dim], name='fc1')\n",
    "      \n",
    "        \n",
    "        w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        # sigmoid elimination\n",
    "        logits = tf.add(tf.matmul(fc1, w2), b2, name='logits')\n",
    "        acted_out = tf.nn.sigmoid(logits)\n",
    "        return logits\n",
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hellofffkevin\n"
    }
   ],
   "source": [
    "###### THIS IS TRAINING THE MODEL\n",
    "\n",
    "def train():\n",
    "    random_dim = 100\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "        # placeholders\n",
    "        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
    "        random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n",
    "        is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    # gets fake/real images and result to fully establish a working\n",
    "    # generator and discriminator interaction\n",
    "    fake_image = generator(random_input, random_dim, is_train)\n",
    "    \n",
    "    real_result = discriminator(real_image, is_train)\n",
    "    fake_result = discriminator(fake_image, is_train, reuse=True)\n",
    "    \n",
    "    # optimization\n",
    "    d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)  \n",
    "    g_loss = -tf.reduce_mean(fake_result) \n",
    "            \n",
    "\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if 'dis' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'gen' in var.name]\n",
    "    trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n",
    "    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n",
    "    d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n",
    "\n",
    "    \n",
    "    batch_size = BATCH_SIZE\n",
    "    image_batch, samples_num = process_data()\n",
    "    \n",
    "    batch_num = int(samples_num / batch_size)\n",
    "    total_batch = 0\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    ckpt = tf.train.latest_checkpoint('./model/' + version)\n",
    "    saver.restore(sess, save_path)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    # show quantity statistics\n",
    "    print('total training sample num:%d' % samples_num)\n",
    "    print('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n",
    "    print('start training...')\n",
    "    # ACTUAL TRAINING STARTS\n",
    "    for i in range(EPOCH):\n",
    "        print(\"Running epoch {}/{}...\".format(i, EPOCH))\n",
    "        for j in range(batch_num):\n",
    "            print(j)\n",
    "            d_iters = 5\n",
    "            g_iters = 1\n",
    "\n",
    "            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            for k in range(d_iters):\n",
    "                print(k)\n",
    "                train_image = sess.run(image_batch)\n",
    "                sess.run(d_clip)\n",
    "                \n",
    "                # Discriminator update\n",
    "                _, dLoss = sess.run([trainer_d, d_loss],\n",
    "                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n",
    "                print(\"dLoss is \" + str(dLoss))\n",
    "\n",
    "            # Generator update\n",
    "            for k in range(g_iters):\n",
    "                _, gLoss = sess.run([trainer_g, g_loss],\n",
    "                                    feed_dict={random_input: train_noise, is_train: True})\n",
    "\n",
    "            print ('train:[%d/%d],d_loss:%f,g_loss:%f' % (i, j, dLoss, gLoss))\n",
    "            \n",
    "        # save every 500 epoch\n",
    "        if i%500 == 0:\n",
    "            if not os.path.exists('./model/' + version):\n",
    "                os.makedirs('./model/' + version)\n",
    "            saver.save(sess, './model/' +version + '/' + str(i))  \n",
    "\n",
    "        # image save every one epoch\n",
    "        if i%1 == 0:\n",
    "            if not os.path.exists(newFace_path):\n",
    "                os.makedirs(newFace_path)\n",
    "            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n",
    "            # imgtest = imgtest * 255.0\n",
    "            # imgtest.astype(np.uint8)\n",
    "            save_images(imgtest, [8,8] ,newFace_path + '/epoch' + str(i) + '.jpg')\n",
    "            \n",
    "            print('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "print(\"helloooo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Trying to share variable dis/w2, but specified shape (32768, 1) and found shape (104448, 1).",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2c46b8c9a490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-dc28f66a97a6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mreal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfake_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_result\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_result\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This optimizes the discriminator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-64a01bddd456>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(input, is_train, reuse)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n\u001b[0;32m---> 39\u001b[0;31m                              initializer=tf.truncated_normal_initializer(stddev=0.02))\n\u001b[0m\u001b[1;32m     40\u001b[0m         b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n\u001b[1;32m     41\u001b[0m                              initializer=tf.constant_initializer(0.0))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    871\u001b[0m         raise ValueError(\"Trying to share variable %s, but specified shape %s\"\n\u001b[1;32m    872\u001b[0m                          \u001b[0;34m\" and found shape %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                          (name, shape, found_var.get_shape()))\n\u001b[0m\u001b[1;32m    874\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0mdtype_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Trying to share variable dis/w2, but specified shape (32768, 1) and found shape (104448, 1)."
     ]
    }
   ],
   "source": [
    "###RUNNNING THE MODEL\n",
    "\n",
    "\n",
    "train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}