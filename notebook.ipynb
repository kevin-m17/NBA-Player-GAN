
I like this
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[WDM] - Current google-chrome version is 85.0.4183\n[WDM] - Get LATEST driver version for 85.0.4183\n[WDM] - Driver [/Users/kevinmo/.wdm/drivers/chromedriver/mac64/85.0.4183.87/chromedriver] found in cache\n \n"
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "# driver = webdriver.Chrome(\"C:Downloads/chromedriver\")\n",
    "# browser = webdriver.Chrome()\n",
    "\n",
    "URL = \"https://www.nba.com/players\"\n",
    "browser.get(URL)\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, 'html5lib')\n",
    "# time.sleep(1)\n",
    "\n",
    "elem = browser.find_element_by_tag_name(\"body\")\n",
    "\n",
    "no_of_pagedowns = 120\n",
    "\n",
    "while no_of_pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    # time.sleep(0.2)\n",
    "    no_of_pagedowns-=1\n",
    "\n",
    "# after scrolling, I make a new folder\n",
    "src = \"./originalPics\"\n",
    "os.mkdir(src)\n",
    "\n",
    "digit = 1\n",
    "# nbaImages = soup.findAll('img', attrs = {'class':'lazyloaded'})\n",
    "# nbaImages = soup.findAll('img', attrs = {'class':'lazyload'})\n",
    "\n",
    "post_elems = browser.find_elements_by_class_name(\"lazyload\")\n",
    "post_elems = browser.find_elements_by_class_name(\"lazyloaded\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "for post in post_elems:\n",
    "    # get the image link\n",
    "    link = post.get_attribute(\"data-src\")\n",
    "    if link[:2] == \"//\":\n",
    "        link = \"https://\" + link[2:]\n",
    "\n",
    "    if count == 250:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    # name of the file\n",
    "    filename = \"nba\" + str(count)\n",
    "\n",
    "    # actually write the image in the folder\n",
    "    mergeFile = os.path.join(src, filename + \".jpeg\")\n",
    "    output = open(mergeFile, 'wb')\n",
    "    output.write(urllib.request.urlopen(link).read())\n",
    "    output.close()\n",
    "\n",
    "# for img in nbaImages:\n",
    "#     link = img.get('data-src')\n",
    "\n",
    "#     if link[:2] == \"//\":\n",
    "#         link = \"https://\" + link[2:]\n",
    "#     print(link) \n",
    "\n",
    "#     if digit == 351:\n",
    "#         break\n",
    "\n",
    "#     strVal = str(digit)\n",
    "#     filename = \"nba\" + strVal\n",
    "#     digit += 1\n",
    "\n",
    "#     mergeFile = os.path.join(src, filename + \".jpeg\")\n",
    "#     output = open(mergeFile, 'wb')\n",
    "#     output.write(urllib.request.urlopen(link).read())\n",
    "#     output.close()\n",
    "\n",
    "# post_elems = browser.find_elements_by_class_name(\"lazyload\")\n",
    "# post_elems = browser.find_elements_by_class_name(\"lazyloaded\")\n",
    "# print(\"aiazng\")\n",
    "# count = 1\n",
    "\n",
    "# for post in post_elems:\n",
    "#     print(str(count))\n",
    "#     count += 1\n",
    "#     print (post.text)\n",
    "# print(\"whats gooddd\")\n",
    "#web scraped NBA photos\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import urllib\n",
    "# import os\n",
    "\n",
    "# URL = \"https://www.nba.com/players\"\n",
    "# r = requests.get(URL)\n",
    "\n",
    "# origin = \"GAN\"\n",
    "# src = \"./originalPics\"\n",
    "\n",
    "# soup = BeautifulSoup(r.content, 'html5lib')\n",
    "# print(soup.prettify()) \n",
    "\n",
    "\n",
    "# digit = 1\n",
    "# nbaImages = soup.findAll('img', attrs = {'class':'lazyloaded'})\n",
    "\n",
    "# os.mkdir(src)\n",
    "\n",
    "# for img in nbaImages:\n",
    "#     link = img.get('data-src')\n",
    "\n",
    "#     if link[:2] == \"//\":\n",
    "#         link = \"https://\" + link[2:]\n",
    "#     print(link) \n",
    "\n",
    "#     if digit == 351:\n",
    "#         break\n",
    "\n",
    "#     strVal = str(digit)\n",
    "#     filename = \"nba\" + strVal\n",
    "#     digit += 1\n",
    "\n",
    "#     mergeFile = os.path.join(src, filename + \".jpeg\")\n",
    "#     output = open(mergeFile, 'wb')\n",
    "#     output.write(urllib.request.urlopen(link).read())\n",
    "#     output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is resizing the images\n",
    "# %matplotlib inline\n",
    "# import os\n",
    "# import PIL\n",
    "# from PIL import Image\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# put images in folder\n",
    "src = \"./originalPics\"\n",
    "dst = \"./resized\"\n",
    "\n",
    "os.mkdir(dst)\n",
    "\n",
    "count = 1\n",
    "\n",
    "for pic in os.listdir(src):\n",
    "    img = cv2.imread(os.path.join(src,pic))\n",
    "    img = cv2.resize(img,(128, 128))\n",
    "    cv2.imwrite(os.path.join(dst,pic), img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "debug\n"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "src = \"resized\"\n",
    "dst = \"./resized_black/\"\n",
    "\n",
    "os.mkdir(dst)\n",
    "\n",
    "for pic in os.listdir(src):\n",
    "    png = Image.open(os.path.join(src,pic))\n",
    "    # print each\n",
    "    if png.mode == 'RGBA':\n",
    "        png.load() # required for png.split()\n",
    "        background = Image.new(\"RGB\", png.size, (0,0,0))\n",
    "        background.paste(png, mask=png.split()[3]) # 3 is the alpha channel\n",
    "        background.save(os.path.join(dst,pic.split('.')[0] + '.jpeg'), 'JPEG') # changed from .jpg\n",
    "    else:\n",
    "        png.convert('RGB')\n",
    "        png.save(os.path.join(dst,pic.split('.')[0] + '.jpeg'), 'JPEG')\n",
    "print(\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: tensorflow==1.15 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (1.15.0)\nRequirement already satisfied: astor>=0.6.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.1)\nRequirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\nRequirement already satisfied: wheel>=0.26 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.1)\nRequirement already satisfied: protobuf>=3.6.1 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (3.13.0)\nRequirement already satisfied: wrapt>=1.11.1 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)\nRequirement already satisfied: termcolor>=1.1.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\nRequirement already satisfied: absl-py>=0.7.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.10.0)\nRequirement already satisfied: gast==0.2.2 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\nRequirement already satisfied: six>=1.10.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.14.0)\nRequirement already satisfied: tensorflow-estimator==1.15.1 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.1)\nRequirement already satisfied: keras-applications>=1.0.8 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\nRequirement already satisfied: grpcio>=1.8.6 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15) (1.32.0)\nRequirement already satisfied: markdown>=2.6.8 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\nRequirement already satisfied: setuptools>=41.0.0 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (46.0.0.post20200309)\nRequirement already satisfied: werkzeug>=0.11.15 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.0)\nRequirement already satisfied: h5py in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.5.0)\nRequirement already satisfied: zipp>=0.5 in /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.2.0)\nWARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\n1.15.0\nhi\n"
    }
   ],
   "source": [
    "!pip install tensorflow==1.15\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import scipy.misc\n",
    "import tf_slim as slim\n",
    "# from python_utils import *\n",
    "from utils import *\n",
    "\n",
    "# slim = tf.contrib.slim\n",
    "print(tf.__version__)\n",
    "\n",
    "# variables needed\n",
    "HEIGHT, WIDTH, CHANNEL = 128, 128, 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 1000\n",
    "version = 'newFaces'\n",
    "newFace_path = './' + version\n",
    "\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello\n"
    }
   ],
   "source": [
    "### LEAKY RELU - if gradient is too small, we add leak to it to keep it going\n",
    "def lrelu(x, n, leak=0.2): \n",
    "    return tf.maximum(x, x * leak, name=n)\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROCESS THE DATA, get two variables (shown at end)\n",
    "\n",
    "def process_data():   \n",
    "    current_dir = os.getcwd()\n",
    "    face_dir = os.path.join(current_dir, 'resized_black')\n",
    "    images = []\n",
    "\n",
    "    # put images in resized black folder\n",
    "    for each in os.listdir(face_dir):\n",
    "        images.append(os.path.join(face_dir,each))\n",
    "\n",
    "    all_images = tf.convert_to_tensor(images, dtype = tf.string)\n",
    "    \n",
    "    images_queue = tf.train.slice_input_producer(\n",
    "                                        [all_images])\n",
    "                                        \n",
    "    content = tf.read_file(images_queue[0])\n",
    "    image = tf.image.decode_jpeg(content, channels = CHANNEL)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta = 0.1)\n",
    "    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1)\n",
    "    # print image.get_shape()\n",
    "    size = [HEIGHT, WIDTH]\n",
    "    image = tf.image.resize_images(image, size)\n",
    "    image.set_shape([HEIGHT,WIDTH,CHANNEL])\n",
    "    # image = image + noise\n",
    "    \n",
    "    # get rid of tf warning\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    iamges_batch = tf.train.shuffle_batch(\n",
    "                                    [image], batch_size = BATCH_SIZE,\n",
    "                                    num_threads = 4, capacity = 200 + 3* BATCH_SIZE,\n",
    "                                    min_after_dequeue = 200)\n",
    "    num_images = len(images)\n",
    "\n",
    "# returns batch of photos and quantity of images\n",
    "    return iamges_batch, num_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello\n"
    }
   ],
   "source": [
    "# generator network\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def generator(input, random_dim, is_train, reuse=False):\n",
    "    # used for network\n",
    "    c4, c8, c16, c32, c64 = 512, 256, 128, 64, 32 \n",
    "    s4 = 4\n",
    "    output_dim = CHANNEL  \n",
    "    with tf.variable_scope('gen') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # build convolution and the layers of the network\n",
    "        #1\n",
    "        w1 = tf.get_variable('w1', shape=[random_dim, s4 * s4 * c4], dtype=tf.float32,\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b1 = tf.get_variable('b1', shape=[c4 * s4 * s4], dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "        flat_conv1 = tf.add(tf.matmul(input, w1), b1, name='flat_conv1')\n",
    "        conv1 = tf.reshape(flat_conv1, shape=[-1, s4, s4, c4], name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
    "        act1 = tf.nn.relu(bn1, name='act1')\n",
    "        #2\n",
    "        conv2 = tf.layers.conv2d_transpose(act1, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = tf.nn.relu(bn2, name='act2')\n",
    "        #3\n",
    "        conv3 = tf.layers.conv2d_transpose(act2, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = tf.nn.relu(bn3, name='act3')\n",
    "        #4\n",
    "        conv4 = tf.layers.conv2d_transpose(act3, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = tf.nn.relu(bn4, name='act4')\n",
    "        #5\n",
    "        conv5 = tf.layers.conv2d_transpose(act4, c64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv5')\n",
    "        bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n",
    "        act5 = tf.nn.relu(bn5, name='act5')\n",
    "        \n",
    "        #6\n",
    "        conv6 = tf.layers.conv2d_transpose(act5, output_dim, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv6')\n",
    "        # bn6 = tf.contrib.layers.batch_norm(conv6, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn6')\n",
    "        act6 = tf.nn.tanh(conv6, name='act6')\n",
    "        return act6\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello\n"
    }
   ],
   "source": [
    "#### discriminator network\n",
    "def discriminator(input, is_train, reuse=False):\n",
    "    c2, c4, c8, c16 = 64, 128, 256, 512  \n",
    "    with tf.variable_scope('dis') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # layers of discriminator network\n",
    "        #1\n",
    "        conv1 = tf.layers.conv2d(input, c2, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn1')\n",
    "        act1 = lrelu(conv1, n='act1')\n",
    "        #2\n",
    "        conv2 = tf.layers.conv2d(act1, c4, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = lrelu(bn2, n='act2')\n",
    "        #3\n",
    "        conv3 = tf.layers.conv2d(act2, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = lrelu(bn3, n='act3')\n",
    "         #4\n",
    "        conv4 = tf.layers.conv2d(act3, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = lrelu(bn4, n='act4')\n",
    "       \n",
    "        # start from 4th layer\n",
    "        dim = int(np.prod(act4.get_shape()[1:]))\n",
    "        fc1 = tf.reshape(act4, shape=[-1, dim], name='fc1')\n",
    "      \n",
    "        \n",
    "        w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        # sigmoid elimination\n",
    "        logits = tf.add(tf.matmul(fc1, w2), b2, name='logits')\n",
    "        acted_out = tf.nn.sigmoid(logits)\n",
    "        return logits\n",
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "helloooo\n"
    }
   ],
   "source": [
    "###### THIS IS TRAINING THE MODEL\n",
    "\n",
    "def train():\n",
    "    random_dim = 100\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "        # placeholders\n",
    "        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
    "        random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n",
    "        is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    # gets fake/real images and result to fully establish a working\n",
    "    # generator and discriminator interaction\n",
    "    fake_image = generator(random_input, random_dim, is_train)\n",
    "    \n",
    "    real_result = discriminator(real_image, is_train)\n",
    "    fake_result = discriminator(fake_image, is_train, reuse=True)\n",
    "    \n",
    "    # optimization\n",
    "    d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)  \n",
    "    g_loss = -tf.reduce_mean(fake_result) \n",
    "            \n",
    "\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if 'dis' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'gen' in var.name]\n",
    "    trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n",
    "    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n",
    "    d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n",
    "\n",
    "    \n",
    "    batch_size = BATCH_SIZE\n",
    "    image_batch, samples_num = process_data()\n",
    "    \n",
    "    batch_num = int(samples_num / batch_size)\n",
    "    total_batch = 0\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    ckpt = tf.train.latest_checkpoint('./model/' + version)\n",
    "    saver.restore(sess, save_path)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    # show quantity statistics\n",
    "    print('total training sample num:%d' % samples_num)\n",
    "    print('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n",
    "    print('start training...')\n",
    "    # ACTUAL TRAINING STARTS\n",
    "    for i in range(EPOCH):\n",
    "        print(\"Running epoch {}/{}...\".format(i, EPOCH))\n",
    "        for j in range(batch_num):\n",
    "            print(j)\n",
    "            d_iters = 5\n",
    "            g_iters = 1\n",
    "\n",
    "            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            for k in range(d_iters):\n",
    "                print(k)\n",
    "                train_image = sess.run(image_batch)\n",
    "                sess.run(d_clip)\n",
    "                \n",
    "                # Discriminator update\n",
    "                _, dLoss = sess.run([trainer_d, d_loss],\n",
    "                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n",
    "                print(\"dLoss is \" + str(dLoss))\n",
    "\n",
    "            # Generator update\n",
    "            for k in range(g_iters):\n",
    "                _, gLoss = sess.run([trainer_g, g_loss],\n",
    "                                    feed_dict={random_input: train_noise, is_train: True})\n",
    "\n",
    "            print ('train:[%d/%d],d_loss:%f,g_loss:%f' % (i, j, dLoss, gLoss))\n",
    "            \n",
    "        # save every 500 epoch\n",
    "        if i%500 == 0:\n",
    "            if not os.path.exists('./model/' + version):\n",
    "                os.makedirs('./model/' + version)\n",
    "            saver.save(sess, './model/' +version + '/' + str(i))  \n",
    "\n",
    "        # image save every one epoch\n",
    "        if i%1 == 0:\n",
    "            if not os.path.exists(newFace_path):\n",
    "                os.makedirs(newFace_path)\n",
    "            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n",
    "            # imgtest = imgtest * 255.0\n",
    "            # imgtest.astype(np.uint8)\n",
    "            save_images(imgtest, [8,8] ,newFace_path + '/epoch' + str(i) + '.jpg')\n",
    "            \n",
    "            print('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "print(\"helloooo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From <ipython-input-8-a8bb2dd0818f>:26: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.keras.layers.Conv2DTranspose` instead.\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:1279: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `layer.__call__` method instead.\nWARNING:tensorflow:From <ipython-input-9-8930592fbb5e>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.keras.layers.Conv2D` instead.\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From <ipython-input-7-2b331ce5635e>:15: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:373: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:319: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nWARNING:tensorflow:From /Users/kevinmo/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nWARNING:tensorflow:From <ipython-input-7-2b331ce5635e>:35: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\nINFO:tensorflow:Restoring parameters from /tmp/model.ckpt\nWARNING:tensorflow:From <ipython-input-10-8875eed0950c>:46: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\ntotal training sample num:250\nbatch size: 64, batch num per epoch: 3, epoch num: 1000\nstart training...\nRunning epoch 0/1000...\n0\n0\ndLoss is 0.32248628\n1\ndLoss is -5.448246\n2\ndLoss is -10.48378\n3\ndLoss is -15.561177\n4\ndLoss is -20.824097\ntrain:[0/0],d_loss:-20.824097,g_loss:10.800629\n1\n0\ndLoss is -23.074553\n1\ndLoss is -29.198511\n2\ndLoss is -34.717045\n3\ndLoss is -40.084583\n4\ndLoss is -44.737587\ntrain:[0/1],d_loss:-44.737587,g_loss:23.332748\n2\n0\ndLoss is -49.238094\n1\ndLoss is -55.46295\n2\ndLoss is -61.456623\n3\ndLoss is -67.36188\n4\ndLoss is -74.32984\ntrain:[0/2],d_loss:-74.329842,g_loss:38.852249\ntrain:[0],d_loss:-74.329842,g_loss:38.852249\nRunning epoch 1/1000...\n0\n0\ndLoss is -76.40932\n1\ndLoss is -83.063126\n2\ndLoss is -90.59418\n3\ndLoss is -96.39752\n4\ndLoss is -101.68294\ntrain:[1/0],d_loss:-101.682938,g_loss:54.662327\n1\n0\ndLoss is -102.6113\n1\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-576a3c6bc2ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8875eed0950c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# Discriminator update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 _, dLoss = sess.run([trainer_d, d_loss],\n\u001b[0;32m---> 68\u001b[0;31m                                     feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dLoss is \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###RUNNNING THE MODEL\n",
    "\n",
    "\n",
    "train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
